{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8W3eEcCowKml"
      },
      "outputs": [],
      "source": [
        "!pip install openai-whisper\n",
        "!pip install flask\n",
        "!pip install python-multipart  # 파일 업로드 시 필요\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install librosa\n",
        "!pip install pandas\n",
        "!pip install diffusers\n",
        "!pip install rapidfuzz  # (옵션) 더 빠른 유사도 측정용\n",
        "!pip install Levenshtein  # (옵션) 정확한 거리 기반 유사도 측정용\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rmVFoimwVX4"
      },
      "outputs": [],
      "source": [
        "!apt update && apt install -y ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQGmiFLtwvq-"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install torch torchaudio\n",
        "!pip install librosa numpy soundfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ4olS8-JnYa"
      },
      "outputs": [],
      "source": [
        "!pip install hangul-romanize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77MIME4tPflS"
      },
      "outputs": [],
      "source": [
        "!pip install flask-ngrok pyngrok --quiet  # ⬅️ 최초 1회 실행 필요\n",
        "!pip install pyngrok --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtaHkvtWRB9l"
      },
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken 2ydg9rJPDW0o04b2Lxoacv8v0pw_6oK7D152GLHfWBuHhpme3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BatAJE9VP7Gs",
        "outputId": "f6be5e15-db3b-46c0-f11b-2d57d6017480"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 91.2MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching ngrok on static domain...\n",
            "Static domain ready: https://wise-positively-octopus.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5001\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2025 13:51:19] \"POST /api/analyze-audio HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2025 13:51:58] \"POST /api/analyze-audio HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2025 13:52:19] \"POST /api/analyze-audio HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2025 13:52:47] \"POST /api/analyze-audio HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2025 13:53:25] \"POST /api/analyze-audio HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2025 13:53:25] \"POST /api/analyze-audio HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2025 13:54:01] \"POST /api/analyze-audio HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2025 13:54:14] \"POST /api/analyze-audio HTTP/1.1\" 200 -\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "INFO:werkzeug:127.0.0.1 - - [18/Jun/2025 13:54:33] \"POST /api/analyze-audio HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import whisper\n",
        "import os\n",
        "import tempfile\n",
        "import difflib\n",
        "import subprocess\n",
        "import time\n",
        "import requests\n",
        "\n",
        "from hangul_romanize import Transliter\n",
        "from hangul_romanize.rule import academic\n",
        "\n",
        "# 설정\n",
        "PORT = 5001\n",
        "STATIC_DOMAIN = \"wise-positively-octopus.ngrok-free.app\"\n",
        "\n",
        "# Whisper 모델\n",
        "transliter = Transliter(academic)\n",
        "app = Flask(__name__)\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# 예시 문장\n",
        "sentence_dict = {\n",
        "    \"1\": \"오늘은 날씨가 아주 맑아요.\",\n",
        "    \"2\": \"저는 한국어를 배우고 있습니다.\",\n",
        "    \"3\": \"학교에 가는 길에 친구를 만났어요.\",\n",
        "    \"4\": \"사과와 바나나를 샀습니다.\",\n",
        "    \"5\": \"내일 같이 점심 먹을까요?\",\n",
        "    \"6\": \"저녁에 공원에서 산책했어요.\",\n",
        "    \"7\": \"책상 위에 연필이 있어요.\",\n",
        "    \"8\": \"내일은 중요한 시험이 있습니다.\",\n",
        "    \"9\": \"머리가 아파서 병원에 왔어요.\",\n",
        "    \"10\": \"지하철을 타고 회사에 갑니다.\"\n",
        "}\n",
        "\n",
        "def korean_to_roman(text):\n",
        "    try:\n",
        "        return transliter.translit(text)\n",
        "    except Exception as e:\n",
        "        print(\"Romanization Error:\", e)\n",
        "        return text.lower()\n",
        "\n",
        "@app.route('/api/analyze-audio', methods=['POST'])\n",
        "def analyze_audio():\n",
        "    try:\n",
        "\n",
        "        audio_file = request.files['audio']\n",
        "        sentenceId = request.form['sentenceId']\n",
        "        userId = request.form.get('userId', 'test-user')\n",
        "\n",
        "        if sentenceId not in sentence_dict:\n",
        "            return jsonify({\"error\": \"Invalid sentenceId\"}), 400\n",
        "\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp:\n",
        "            audio_file.save(tmp.name)\n",
        "            audio_path = tmp.name\n",
        "\n",
        "        result = model.transcribe(audio_path, language='ko')\n",
        "        transcript = result[\"text\"].strip()\n",
        "        os.unlink(audio_path)\n",
        "\n",
        "        target = sentence_dict[sentenceId]\n",
        "        user_roman = korean_to_roman(transcript)\n",
        "        target_roman = korean_to_roman(target)\n",
        "\n",
        "        matcher = difflib.SequenceMatcher(None, user_roman, target_roman)\n",
        "        score = round(matcher.ratio() * 100)\n",
        "\n",
        "        diff_list = []\n",
        "        for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
        "            if tag == 'equal':\n",
        "                continue\n",
        "            error_type = {\n",
        "                'replace': 'substitute',\n",
        "                'delete': 'insert',\n",
        "                'insert': 'delete'\n",
        "            }.get(tag, 'mismatch')\n",
        "\n",
        "            diff_list.append({\n",
        "                \"user\": user_roman[i1:i2],\n",
        "                \"expected\": target_roman[j1:j2],\n",
        "                \"error\": error_type\n",
        "            })\n",
        "\n",
        "        feedback = \"상\" if score > 85 else \"중\" if score > 60 else \"하\"\n",
        "\n",
        "        return jsonify({\n",
        "            \"score\": score,\n",
        "            \"user_pronunciation\": user_roman,\n",
        "            \"target_pronunciation\": target_roman,\n",
        "            \"diff\": diff_list\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "# ngrok 실행\n",
        "print(\"Launching ngrok on static domain...\")\n",
        "subprocess.Popen(['ngrok', 'http', f'--domain={STATIC_DOMAIN}', str(PORT)])\n",
        "time.sleep(5)  # ngrok 연결 대기\n",
        "print(f\"Static domain ready: https://{STATIC_DOMAIN}\")\n",
        "\n",
        "# Flask 실행\n",
        "app.run(port=PORT)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}